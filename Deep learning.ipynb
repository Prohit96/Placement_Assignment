{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b5ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 1 -\n",
    "Implement 3 different CNN architectures with a comparison table for the MNSIT\n",
    "dataset using the Tensorflow library.\n",
    "Note -\n",
    "1. The model parameters for each architecture should not be more than 8000\n",
    "parameters\n",
    "2. Code comments should be given for proper code understanding.\n",
    "3. The minimum accuracy for each accuracy should be at least 96%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c651add0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf in c:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.20.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install protobuf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c669a897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 - 33s - loss: 0.2188 - accuracy: 0.9368 - 33s/epoch - 70ms/step\n",
      "Epoch 2/10\n",
      "469/469 - 26s - loss: 0.0694 - accuracy: 0.9793 - 26s/epoch - 55ms/step\n",
      "Epoch 3/10\n",
      "469/469 - 24s - loss: 0.0482 - accuracy: 0.9862 - 24s/epoch - 52ms/step\n",
      "Epoch 4/10\n",
      "469/469 - 26s - loss: 0.0355 - accuracy: 0.9892 - 26s/epoch - 54ms/step\n",
      "Epoch 5/10\n",
      "469/469 - 27s - loss: 0.0257 - accuracy: 0.9924 - 27s/epoch - 58ms/step\n",
      "Epoch 6/10\n",
      "469/469 - 27s - loss: 0.0202 - accuracy: 0.9941 - 27s/epoch - 57ms/step\n",
      "Epoch 7/10\n",
      "469/469 - 25s - loss: 0.0150 - accuracy: 0.9954 - 25s/epoch - 54ms/step\n",
      "Epoch 8/10\n",
      "469/469 - 24s - loss: 0.0115 - accuracy: 0.9966 - 24s/epoch - 52ms/step\n",
      "Epoch 9/10\n",
      "469/469 - 26s - loss: 0.0084 - accuracy: 0.9975 - 26s/epoch - 56ms/step\n",
      "Epoch 10/10\n",
      "469/469 - 26s - loss: 0.0067 - accuracy: 0.9979 - 26s/epoch - 55ms/step\n",
      "Simple CNN Accuracy: 0.9858999848365784\n",
      "Epoch 1/10\n",
      "469/469 - 33s - loss: 0.3341 - accuracy: 0.8987 - 33s/epoch - 71ms/step\n",
      "Epoch 2/10\n",
      "469/469 - 31s - loss: 0.1334 - accuracy: 0.9610 - 31s/epoch - 65ms/step\n",
      "Epoch 3/10\n",
      "469/469 - 32s - loss: 0.1001 - accuracy: 0.9706 - 32s/epoch - 68ms/step\n",
      "Epoch 4/10\n",
      "469/469 - 32s - loss: 0.0847 - accuracy: 0.9751 - 32s/epoch - 67ms/step\n",
      "Epoch 5/10\n",
      "469/469 - 31s - loss: 0.0726 - accuracy: 0.9769 - 31s/epoch - 66ms/step\n",
      "Epoch 6/10\n",
      "469/469 - 35s - loss: 0.0651 - accuracy: 0.9799 - 35s/epoch - 74ms/step\n",
      "Epoch 7/10\n",
      "469/469 - 36s - loss: 0.0591 - accuracy: 0.9820 - 36s/epoch - 76ms/step\n",
      "Epoch 8/10\n",
      "469/469 - 36s - loss: 0.0530 - accuracy: 0.9837 - 36s/epoch - 77ms/step\n",
      "Epoch 9/10\n",
      "469/469 - 34s - loss: 0.0507 - accuracy: 0.9843 - 34s/epoch - 73ms/step\n",
      "Epoch 10/10\n",
      "469/469 - 34s - loss: 0.0463 - accuracy: 0.9850 - 34s/epoch - 73ms/step\n",
      "CNN with Dropout Accuracy: 0.9879999756813049\n",
      "Epoch 1/10\n",
      "469/469 - 46s - loss: 0.2149 - accuracy: 0.9376 - 46s/epoch - 98ms/step\n",
      "Epoch 2/10\n",
      "469/469 - 48s - loss: 0.0552 - accuracy: 0.9832 - 48s/epoch - 103ms/step\n",
      "Epoch 3/10\n",
      "469/469 - 44s - loss: 0.0396 - accuracy: 0.9877 - 44s/epoch - 93ms/step\n",
      "Epoch 4/10\n",
      "469/469 - 45s - loss: 0.0297 - accuracy: 0.9907 - 45s/epoch - 96ms/step\n",
      "Epoch 5/10\n",
      "469/469 - 44s - loss: 0.0234 - accuracy: 0.9928 - 44s/epoch - 93ms/step\n",
      "Epoch 6/10\n",
      "469/469 - 50s - loss: 0.0188 - accuracy: 0.9939 - 50s/epoch - 106ms/step\n",
      "Epoch 7/10\n",
      "469/469 - 48s - loss: 0.0145 - accuracy: 0.9956 - 48s/epoch - 101ms/step\n",
      "Epoch 8/10\n",
      "469/469 - 45s - loss: 0.0119 - accuracy: 0.9960 - 45s/epoch - 95ms/step\n",
      "Epoch 9/10\n",
      "469/469 - 39s - loss: 0.0097 - accuracy: 0.9969 - 39s/epoch - 84ms/step\n",
      "Epoch 10/10\n",
      "469/469 - 36s - loss: 0.0098 - accuracy: 0.9967 - 36s/epoch - 77ms/step\n",
      "Deeper CNN Accuracy: 0.9904999732971191\n",
      "              Model  Accuracy  Parameters\n",
      "0        Simple CNN    0.9859      693962\n",
      "1  CNN with Dropout    0.9880      693962\n",
      "2        Deeper CNN    0.9905      225034\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Define CNN architectures\n",
    "\n",
    "# Model 1: Simple CNN\n",
    "model1 = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(28, 28, 1), input_shape=(28, 28)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Model 2: CNN with Dropout\n",
    "model2 = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(28, 28, 1), input_shape=(28, 28)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Model 3: Deeper CNN\n",
    "model3 = tf.keras.Sequential([\n",
    "    layers.Reshape(target_shape=(28, 28, 1), input_shape=(28, 28)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train the models\n",
    "models = [model1, model2, model3]\n",
    "model_names = ['Simple CNN', 'CNN with Dropout', 'Deeper CNN']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(x_train, y_train, epochs=10, batch_size=128, verbose=2)\n",
    "    \n",
    "    _, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    print(f'{model_names[i]} Accuracy: {accuracy}')\n",
    "\n",
    "# Create a comparison table\n",
    "import pandas as pd\n",
    "\n",
    "comparison_data = {\n",
    "    'Model': model_names,\n",
    "    'Accuracy': [model.evaluate(x_test, y_test, verbose=0)[1] for model in models],\n",
    "    'Parameters': [model.count_params() for model in models]\n",
    "}\n",
    "\n",
    "comparison_table = pd.DataFrame(comparison_data)\n",
    "print(comparison_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cec7a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 2 -\n",
    "Implement 5 different CNN architectures with a comparison table for CIFAR 10\n",
    "dataset using the PyTorch library\n",
    "Note -\n",
    "1. The model parameters for each architecture should not be more than 10000\n",
    "parameters\n",
    "2 Code comments should be given for proper code understanding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1af47f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture\tParameters\n",
      "---------------------------------\n",
      "Net1\t\t\t164298\n",
      "Net2\t\t\t328586\n",
      "Net3\t\t\t82154\n",
      "Net4\t\t\t4197578\n",
      "Net5\t\t\t87018\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the first CNN architecture\n",
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.fc = nn.Linear(16 * 32 * 32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = x.view(-1, 16 * 32 * 32)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Define the second CNN architecture\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.fc = nn.Linear(32 * 32 * 32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = x.view(-1, 32 * 32 * 32)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Define the third CNN architecture\n",
    "class Net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3, padding=1)\n",
    "        self.fc = nn.Linear(8 * 32 * 32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = x.view(-1, 8 * 32 * 32)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Define the fourth CNN architecture\n",
    "class Net4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net4, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(16 * 32 * 32, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = x.view(-1, 16 * 32 * 32)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define the fifth CNN architecture\n",
    "class Net5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.fc = nn.Linear(32 * 16 * 16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(-1, 32 * 16 * 16)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Create a dictionary to store the models\n",
    "models = {\n",
    "    'Net1': Net1(),\n",
    "    'Net2': Net2(),\n",
    "    'Net3': Net3(),\n",
    "    'Net4': Net4(),\n",
    "    'Net5': Net5()\n",
    "}\n",
    "\n",
    "# Function to count the number of parameters in a model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Print the comparison table\n",
    "print(\"Model Architecture\\tParameters\")\n",
    "print(\"---------------------------------\")\n",
    "for name, model in models.items():\n",
    "    num_params = count_parameters(model)\n",
    "    print(f\"{name}\\t\\t\\t{num_params}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57471118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.0.1)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: torchvision in c:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (1.21.4)\n",
      "Requirement already satisfied: requests in c:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (2.26.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchvision) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchvision) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc8f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question 3 -\n",
    "Train a Pure CNN with less than 10000 trainable parameters using the MNIST\n",
    "Dataset having minimum validation accuracy of 99.40%\n",
    "Note -\n",
    "1. Code comments should be given for proper code understanding.\n",
    "2. Implement in both PyTorch and Tensorflow respectively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5576140",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (2048) to match target batch_size (128).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15380/636908863.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1174\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[1;32mc:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3027\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3028\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3029\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (2048) to match target batch_size (128)."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = x.view(-1, 32 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Load the MNIST dataset and apply transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "# Set the batch size for training and testing\n",
    "batch_size_train = 128\n",
    "batch_size_test = len(test_dataset)  # Use the entire test set at once for evaluation\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size_test, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = Net()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {running_loss:.4f} | Validation Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Check if the desired accuracy is achieved\n",
    "    if accuracy >= 99.40:\n",
    "        print(\"Desired accuracy achieved. Stopping training.\")\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56624050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 70s 148ms/step - loss: 0.1530 - accuracy: 0.9551\n",
      "Validation Accuracy: 98.07%\n",
      "469/469 [==============================] - 71s 152ms/step - loss: 0.0440 - accuracy: 0.9863\n",
      "Validation Accuracy: 98.37%\n",
      "469/469 [==============================] - 67s 142ms/step - loss: 0.0249 - accuracy: 0.9923\n",
      "Validation Accuracy: 98.79%\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 0.0147 - accuracy: 0.9954\n",
      "Validation Accuracy: 98.67%\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0110 - accuracy: 0.9966\n",
      "Validation Accuracy: 98.59%\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.0092 - accuracy: 0.9967\n",
      "Validation Accuracy: 98.88%\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 0.0071 - accuracy: 0.9974\n",
      "Validation Accuracy: 98.84%\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.0049 - accuracy: 0.9981\n",
      "Validation Accuracy: 98.83%\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.0059 - accuracy: 0.9980\n",
      "Validation Accuracy: 98.97%\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 0.0031 - accuracy: 0.9990\n",
      "Validation Accuracy: 98.84%\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.0054 - accuracy: 0.9981\n",
      "Validation Accuracy: 98.79%\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.0046 - accuracy: 0.9983\n",
      "Validation Accuracy: 98.96%\n",
      "469/469 [==============================] - 69s 148ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Validation Accuracy: 98.91%\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Validation Accuracy: 98.96%\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "Validation Accuracy: 98.63%\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.0021 - accuracy: 0.9992\n",
      "Validation Accuracy: 98.87%\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 0.0020 - accuracy: 0.9994\n",
      "Validation Accuracy: 98.98%\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 0.0022 - accuracy: 0.9991\n",
      "Validation Accuracy: 98.67%\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.0021 - accuracy: 0.9994\n",
      "Validation Accuracy: 98.85%\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Validation Accuracy: 98.91%\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 0.0033 - accuracy: 0.9988\n",
      "Validation Accuracy: 98.80%\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.0015 - accuracy: 0.9995\n",
      "Validation Accuracy: 98.90%\n",
      "469/469 [==============================] - 67s 142ms/step - loss: 3.4693e-04 - accuracy: 0.9999\n",
      "Validation Accuracy: 98.93%\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 9.8040e-05 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 7.3032e-06 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 4.6106e-06 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 3.4254e-06 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 67s 142ms/step - loss: 2.6238e-06 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 2.0400e-06 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 1.5969e-06 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 1.2551e-06 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 9.8826e-07 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 7.7936e-07 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.07%\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 6.1446e-07 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.07%\n",
      "469/469 [==============================] - 67s 142ms/step - loss: 4.8433e-07 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.07%\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 3.8235e-07 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.06%\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 3.0144e-07 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.06%\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 2.3772e-07 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.06%\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 1.8728e-07 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.05%\n",
      "469/469 [==============================] - 67s 142ms/step - loss: 1.4750e-07 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.06%\n",
      "469/469 [==============================] - 65s 140ms/step - loss: 1.1632e-07 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.06%\n",
      "469/469 [==============================] - 67s 142ms/step - loss: 9.1860e-08 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.06%\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 7.2650e-08 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.06%\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 5.7582e-08 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.06%\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 4.5701e-08 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.06%\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 3.6480e-08 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.07%\n",
      "469/469 [==============================] - 72s 153ms/step - loss: 2.9127e-08 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 2.3411e-08 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.07%\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 1.8835e-08 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 1.5191e-08 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 67s 142ms/step - loss: 1.2362e-08 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 69s 148ms/step - loss: 1.0033e-08 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 72s 153ms/step - loss: 8.1897e-09 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 74s 158ms/step - loss: 6.7453e-09 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 5.5750e-09 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "469/469 [==============================] - 73s 157ms/step - loss: 4.6194e-09 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "469/469 [==============================] - 77s 164ms/step - loss: 3.8366e-09 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 3.2564e-09 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "469/469 [==============================] - 73s 156ms/step - loss: 2.6842e-09 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 77s 164ms/step - loss: 2.2570e-09 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "469/469 [==============================] - 74s 158ms/step - loss: 1.8895e-09 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 75s 159ms/step - loss: 1.5914e-09 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 74s 158ms/step - loss: 1.3709e-09 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 1.1702e-09 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 73s 157ms/step - loss: 1.0292e-09 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 78s 167ms/step - loss: 8.8612e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 77s 165ms/step - loss: 7.6294e-10 - accuracy: 1.0000s - loss: 7.6401e-10 - ac\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 79s 169ms/step - loss: 6.8943e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 76s 161ms/step - loss: 6.2188e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 83s 178ms/step - loss: 5.5830e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 82s 175ms/step - loss: 4.9869e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 75s 160ms/step - loss: 4.7485e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 78s 166ms/step - loss: 4.5498e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 75s 159ms/step - loss: 4.2915e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 79s 168ms/step - loss: 4.1922e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.07%\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 3.9339e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 3.8147e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "469/469 [==============================] - 66s 142ms/step - loss: 3.8544e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 3.6558e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 3.6955e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 3.4769e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 3.4372e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 62s 133ms/step - loss: 3.3379e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 62s 133ms/step - loss: 3.3379e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.07%\n",
      "469/469 [==============================] - 62s 133ms/step - loss: 3.2981e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.07%\n",
      "469/469 [==============================] - 62s 132ms/step - loss: 3.1789e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.07%\n",
      "469/469 [==============================] - 63s 133ms/step - loss: 3.1988e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.07%\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 3.1988e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 3.0994e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.07%\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 3.0200e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 70s 150ms/step - loss: 3.0398e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 2.8610e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 63s 134ms/step - loss: 2.9008e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 63s 133ms/step - loss: 2.8213e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 63s 135ms/step - loss: 2.9405e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 2.7418e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 2.7617e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.07%\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 2.7617e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.07%\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 2.5233e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.07%\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 2.5829e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.07%\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 2.5829e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.06%\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 2.5034e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 2.5233e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.06%\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 2.3444e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 69s 147ms/step - loss: 2.3444e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 2.2650e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 2.2451e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "469/469 [==============================] - 63s 135ms/step - loss: 2.2252e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 2.1259e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 2.1060e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 74s 157ms/step - loss: 2.0067e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 71s 152ms/step - loss: 2.0067e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 72s 154ms/step - loss: 1.8676e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.07%\n",
      "469/469 [==============================] - 69s 147ms/step - loss: 1.8477e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 65s 139ms/step - loss: 1.7484e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 64s 135ms/step - loss: 1.8279e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.07%\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 1.5696e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.07%\n",
      "469/469 [==============================] - 64s 136ms/step - loss: 1.5299e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 73s 156ms/step - loss: 1.6093e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 1.4504e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 1.4305e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 69s 147ms/step - loss: 1.3908e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 1.3312e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 62s 132ms/step - loss: 1.2914e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 62s 132ms/step - loss: 1.2517e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.08%\n",
      "469/469 [==============================] - 62s 133ms/step - loss: 1.1325e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "469/469 [==============================] - 4543s 10s/step - loss: 1.0928e-10 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 9.5367e-11 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 9.5367e-11 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "469/469 [==============================] - 63s 135ms/step - loss: 9.1394e-11 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 8.7420e-11 - accuracy: 1.0000\n",
      "Validation Accuracy: 99.09%\n",
      "167/469 [=========>....................] - ETA: 45s - loss: 5.0191e-11 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14760/4281165707.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# Training loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Validation Accuracy: {val_accuracy * 100:.2f}%\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shrik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Load the MNIST dataset and preprocess the data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "# Set the minimum validation accuracy required\n",
    "desired_accuracy = 99.40\n",
    "\n",
    "# Define the CNN architecture\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "# Training loop\n",
    "while True:\n",
    "    model.fit(x_train, y_train, batch_size=128, epochs=1, verbose=1)\n",
    "    _, val_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Check if the desired accuracy is achieved\n",
    "    if val_accuracy * 100 >= desired_accuracy:\n",
    "        print(\"Desired accuracy achieved. Stopping training.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519a71d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
